# src/rl/train_compatibility.py
"""
–û–±—É—á–µ–Ω–∏–µ Compatibility Agent (–ø–µ—Ä–≤—ã–π –∞–≥–µ–Ω—Ç –≤ Sequential pipeline).
"""
from sb3_contrib import MaskablePPO
from sb3_contrib.common.wrappers import ActionMasker
from src.backend.db.queries import fetch_candidate_products
from src.agent.compatibility_env import CompatibilityEnv
import numpy as np



def mask_fn(env):
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è ActionMasker wrapper"""
    return env.action_masks()



def make_env(seed=0):
    """–°–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Compatibility Agent"""
    constraints = {
        "budget_rub": 1500,
        "exclude_tags": [],  # Compatibility Agent –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Ç–µ–≥–∏ (—ç—Ç–æ –∑–∞–¥–∞—á–∞ Profile Agent)
        "include_tags": [],
        "meal_type": ["dinner"],
        "people": 2,
    }
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–≤–∞—Ä—ã –° meal_components
    products = fetch_candidate_products(
        constraints, 
        limit=100,
        require_meal_components=True  # ‚Üê –¢–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã —Å meal_components
    )
    
    print(f"[INFO] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è Compatibility Agent")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ meal_components
    from collections import Counter
    all_components = []
    for p in products:
        all_components.extend(p['meal_components'])
    
    print(f"[INFO] –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ meal_components:")
    for comp, count in Counter(all_components).most_common(10):
        print(f"  {comp}: {count}")
    
    env = CompatibilityEnv(products, constraints, max_steps=15)
    env = ActionMasker(env, mask_fn)
    
    return env



if __name__ == "__main__":
    print("=" * 70)
    print("üé≠ –û–±—É—á–µ–Ω–∏–µ Compatibility Agent")
    print("=" * 70)
    
    env = make_env()
    
    model = MaskablePPO(
        "MlpPolicy",
        env,
        verbose=1,
        learning_rate=3e-4,      # –ù–µ–º–Ω–æ–≥–æ –Ω–∏–∂–µ, —á–µ–º —É –≤–∞—Å (–±—ã–ª–æ 5e-4)
        n_steps=2048,
        batch_size=64,           # –ú–µ–Ω—å—à–µ batch –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        ent_coef=0.5,            # Exploration
        clip_range=0.2,
        gamma=0.99,
        tensorboard_log="./logs/compatibility_agent/"
    )
    
    print("\nüöÄ –û–±—É—á–∞–µ–º 100k —à–∞–≥–æ–≤...")
    model.learn(total_timesteps=100_000, progress_bar=True)
    
    model.save("models/compatibility_agent_v0")
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/compatibility_agent_v0.zip")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º 5 —ç–ø–∏–∑–æ–¥–æ–≤...")
    total_rewards = []
    
    for ep in range(5):
        obs, _ = env.reset()
        ep_reward = 0
        done = False
        
        while not done:
            action, _ = model.predict(obs, deterministic=True)
            obs, reward, terminated, truncated, info = env.step(action)
            ep_reward += reward
            done = terminated or truncated
        
        total_rewards.append(ep_reward)
        
        coverage = info['component_coverage']
        required = ['main_course', 'side_dish', 'beverage']
        required_met = all(coverage.get(comp, False) for comp in required)
        
        print(f"\n  –≠–ø–∏–∑–æ–¥ {ep+1}:")
        print(f"    reward={ep_reward:.1f}, cart={info['cart_size']}, cost={info['total_cost']:.2f}‚ÇΩ")
        print(f"    Required components: {'‚úÖ –í–°–ï' if required_met else '‚ùå –ù–ï –í–°–ï'}")
        print(f"    Coverage: {[k for k, v in coverage.items() if v]}")
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ—Ä–∑–∏–Ω—ã
        env.unwrapped.render()
    
    print(f"\nüìä –°—Ä–µ–¥–Ω–∏–π reward: {np.mean(total_rewards):.1f}")
